{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "65200b84be85425499f558667f4fb461": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_088c672e07cb4dd6b544ad2149f8ab10",
              "IPY_MODEL_3cf30a455cd4498d9bbedbcc25de3660",
              "IPY_MODEL_c9275cb7b0f342b08f899c563c1ed66a",
              "IPY_MODEL_f1bb4c09100a407a8c8136c9aaf1ea03"
            ],
            "layout": "IPY_MODEL_148afc5d78e842079f08629ed8e2f24e"
          }
        },
        "cb0b594a1f6e4cdab4b97ce0619ec2bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a60416a4ea3423d8936a19b9eeb69a1",
            "placeholder": "​",
            "style": "IPY_MODEL_1702f5f59c8d43a094e26f15bb375f86",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "5e219966d8ff440e88389613f6d3dc77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_4068d6bf96f145c5aa9da9e61ad2fa17",
            "placeholder": "​",
            "style": "IPY_MODEL_cc02b0e3725048ca89f5621473bb1c2e",
            "value": ""
          }
        },
        "4a7f665c7ae74fd1b5e0e29b1a3f8cb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_5dde191bb1724cf9a550ba213c78dbc5",
            "style": "IPY_MODEL_bc8cf5300e194299b8ce930c90d25268",
            "value": true
          }
        },
        "0cadc3254a26405ca5a8b213f2436f92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_64875ab7d55d4f139cc6995dff51779c",
            "style": "IPY_MODEL_a79f7f232bb64345888a74273d10d69b",
            "tooltip": ""
          }
        },
        "d1a6f465a90c4a27a07a8104c528aba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a291f2f42d9649dfada94ec8b06df308",
            "placeholder": "​",
            "style": "IPY_MODEL_fb5be2f2a338438cad0cf0a988f32e5f",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "148afc5d78e842079f08629ed8e2f24e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "5a60416a4ea3423d8936a19b9eeb69a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1702f5f59c8d43a094e26f15bb375f86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4068d6bf96f145c5aa9da9e61ad2fa17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc02b0e3725048ca89f5621473bb1c2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5dde191bb1724cf9a550ba213c78dbc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc8cf5300e194299b8ce930c90d25268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64875ab7d55d4f139cc6995dff51779c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a79f7f232bb64345888a74273d10d69b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "a291f2f42d9649dfada94ec8b06df308": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb5be2f2a338438cad0cf0a988f32e5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f60baf4bf43241bf91ba8ca80f0d55e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4b153de455c4e6692cc4a269007232d",
            "placeholder": "​",
            "style": "IPY_MODEL_5934dbcb5ed7485a97e1e9b3b3f3a40e",
            "value": "Connecting..."
          }
        },
        "c4b153de455c4e6692cc4a269007232d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5934dbcb5ed7485a97e1e9b3b3f3a40e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "088c672e07cb4dd6b544ad2149f8ab10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7811c6b43f3f485fae95acfaf48df8d2",
            "placeholder": "​",
            "style": "IPY_MODEL_ff89a34ba87f4017b7368c75514716ca",
            "value": "Token is valid (permission: write)."
          }
        },
        "3cf30a455cd4498d9bbedbcc25de3660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8755fe638e2d4a24b982c29866ad8419",
            "placeholder": "​",
            "style": "IPY_MODEL_54846140000143d6afa331f951f65d7b",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "c9275cb7b0f342b08f899c563c1ed66a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_175e56b4953b414fa87f99a41f686fd5",
            "placeholder": "​",
            "style": "IPY_MODEL_5b04288d7afc486384caa5a5ba78b232",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "f1bb4c09100a407a8c8136c9aaf1ea03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc9d179705a347a79c0be89b98a831f5",
            "placeholder": "​",
            "style": "IPY_MODEL_fdc4e8efe56941cfaf478f48979c51ba",
            "value": "Login successful"
          }
        },
        "7811c6b43f3f485fae95acfaf48df8d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff89a34ba87f4017b7368c75514716ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8755fe638e2d4a24b982c29866ad8419": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54846140000143d6afa331f951f65d7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "175e56b4953b414fa87f99a41f686fd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b04288d7afc486384caa5a5ba78b232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc9d179705a347a79c0be89b98a831f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdc4e8efe56941cfaf478f48979c51ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Whisper\n",
        "Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains without the need for fine-tuning. However, as the model's weight has been released, fine-tuning of the model is possible on custom data. This model can convert speech to text in real time and also perform real time translation of text TO english from other languages. Models like this can be used for a wide range such as Meeting Transcriptions, Call Centers for Customer Assistance, Lecture Transcriptions for students, Subtitling and Captioning etc.\n",
        "[Model Card](https://huggingface.co/openai/whisper-large-v3)"
      ],
      "metadata": {
        "id": "5d9EomG2CIcj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install the Dependencies"
      ],
      "metadata": {
        "id": "yrCKW__pC2b9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9hSMDoaB9uC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3206de6b-d990-48b3-b5d3-8aa6237972ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-24.0\n",
            "Collecting git+https://github.com/huggingface/transformers.git\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-qn5kq187\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-qn5kq187\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 4b3eb19fa7f359d25f62ca9108479f71de912ebc\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.30.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting datasets[audio]\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0.dev0) (3.14.0)\n",
            "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers==4.41.0.dev0)\n",
            "  Downloading huggingface_hub-0.23.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0.dev0) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0.dev0) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0.dev0) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0.dev0) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0.dev0) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.41.0.dev0) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets[audio])\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (2.0.3)\n",
            "Collecting xxhash (from datasets[audio])\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets[audio])\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets[audio]) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (3.9.5)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (0.12.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from datasets[audio]) (0.10.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets[audio]) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.0.dev0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.41.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.41.0.dev0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.41.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.41.0.dev0) (2024.2.2)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->datasets[audio]) (1.16.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (0.58.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.8.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (0.3.7)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->datasets[audio]) (1.0.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets[audio]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets[audio]) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets[audio]) (2024.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->datasets[audio]) (2.22)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa->datasets[audio]) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa->datasets[audio]) (4.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets[audio]) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa->datasets[audio]) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m109.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m661.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.41.0.dev0-py3-none-any.whl size=9091546 sha256=32f1dda0cf8476b439c4c7ad54d0cc08e828f1c5db47eb71f50b9d9ac9a2efaa\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-aocr847l/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\n",
            "Successfully built transformers\n",
            "Installing collected packages: xxhash, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, huggingface-hub, nvidia-cusolver-cu12, transformers, datasets, accelerate\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.40.2\n",
            "    Uninstalling transformers-4.40.2:\n",
            "      Successfully uninstalled transformers-4.40.2\n",
            "Successfully installed accelerate-0.30.1 datasets-2.19.1 dill-0.3.8 huggingface-hub-0.23.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 transformers-4.41.0.dev0 xxhash-3.4.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install --upgrade git+https://github.com/huggingface/transformers.git accelerate datasets[audio]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "65200b84be85425499f558667f4fb461",
            "cb0b594a1f6e4cdab4b97ce0619ec2bc",
            "5e219966d8ff440e88389613f6d3dc77",
            "4a7f665c7ae74fd1b5e0e29b1a3f8cb7",
            "0cadc3254a26405ca5a8b213f2436f92",
            "d1a6f465a90c4a27a07a8104c528aba3",
            "148afc5d78e842079f08629ed8e2f24e",
            "5a60416a4ea3423d8936a19b9eeb69a1",
            "1702f5f59c8d43a094e26f15bb375f86",
            "4068d6bf96f145c5aa9da9e61ad2fa17",
            "cc02b0e3725048ca89f5621473bb1c2e",
            "5dde191bb1724cf9a550ba213c78dbc5",
            "bc8cf5300e194299b8ce930c90d25268",
            "64875ab7d55d4f139cc6995dff51779c",
            "a79f7f232bb64345888a74273d10d69b",
            "a291f2f42d9649dfada94ec8b06df308",
            "fb5be2f2a338438cad0cf0a988f32e5f",
            "f60baf4bf43241bf91ba8ca80f0d55e9",
            "c4b153de455c4e6692cc4a269007232d",
            "5934dbcb5ed7485a97e1e9b3b3f3a40e",
            "088c672e07cb4dd6b544ad2149f8ab10",
            "3cf30a455cd4498d9bbedbcc25de3660",
            "c9275cb7b0f342b08f899c563c1ed66a",
            "f1bb4c09100a407a8c8136c9aaf1ea03",
            "7811c6b43f3f485fae95acfaf48df8d2",
            "ff89a34ba87f4017b7368c75514716ca",
            "8755fe638e2d4a24b982c29866ad8419",
            "54846140000143d6afa331f951f65d7b",
            "175e56b4953b414fa87f99a41f686fd5",
            "5b04288d7afc486384caa5a5ba78b232",
            "bc9d179705a347a79c0be89b98a831f5",
            "fdc4e8efe56941cfaf478f48979c51ba"
          ]
        },
        "id": "qTIgBkZ6EIfF",
        "outputId": "9ec12e4b-eac7-4a88-97ea-a97cf72c95b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "65200b84be85425499f558667f4fb461"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the model"
      ],
      "metadata": {
        "id": "ovhmVoXvzQCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline                    # The imports Required\n",
        "\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"                                     # Code to choose cuda if a GPU is available, the model works without GPU also, but it will take longer to run\n",
        "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "\n",
        "model_id = \"openai/whisper-large-v3\"                                                          # The model to be used, I'm choosing the biggest model as it only has 1.5B parameters and is small enough to fit on Colab's T4 gpu.\n",
        "\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=False, use_safetensors=True\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "\n",
        "pipe = pipeline(                                                                             # The pipeline to run the model\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=model,\n",
        "    tokenizer=processor.tokenizer,\n",
        "    feature_extractor=processor.feature_extractor,\n",
        "    max_new_tokens=128,                                                                     # The maximum number of tokens to generate in the output, more than 128 will need a bigger gpu than colab's T4\n",
        "    chunk_length_s=30,                                                                      # The number of seconds of audio that will be considered as one chunk\n",
        "    batch_size=16,\n",
        "    return_timestamps=True,\n",
        "    torch_dtype=torch_dtype,\n",
        "    device=device,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "5wsMi9yzyqcF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a196b03-ff2f-47f7-fc87-b23d7bb5d64e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing model's Trascription Capabilities\n",
        "To test the model, I will be converting the audio from google's 2024 Keynote event showcasing astra: https://www.youtube.com/watch?v=nXVvvRhiGjI to text."
      ],
      "metadata": {
        "id": "9sNbPuJcDiOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_1 = ('/content/Project Astra_ Our vision for the future of AI assistants.mp3')"
      ],
      "metadata": {
        "id": "0_YPAAihyyDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "result_1 = pipe(audio_1, return_timestamps = True)\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_1 = end_time - start_time\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IqPnLAdGIlZ",
        "outputId": "475898bb-ee9a-4fae-b866-10be8edb7095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_1['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "i0dTmzfWGLxQ",
        "outputId": "59186b25-304d-4909-8734-1fd2e0cd4f7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Okay, let's do some tests. Tell me when you see something that makes sound. I see a speaker which makes sound. What is that part of the speaker called? That is the tweeter. It produces high frequency sounds. Give me a creative alliteration about these. Creative crayons color cheerfully. They certainly craft colorful creations. What does that part of the code do? This code defines encryption and decryption functions. It seems to use AESCBC encryption to encode and decode data based on a key and an initialization vector, IV. That's right. on a key and an initialization vector, IV. That's right. What neighborhood do you think I'm in? This appears to be the King's Cross area of London. It is known for its railway station and transportation connections. Do you remember where you saw my glasses? Yes, I do. Your glasses were on the desk near a red apple. What can I add here to make this system faster? Adding a cache between the server and database could improve speed. What does this remind you of? Schrodinger's cat. All right. Give me a band name for this duo. Golden Stripes. Nice. Thanks, Gemini.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_1['chunks']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjqFnqwrHrQY",
        "outputId": "8204cdb4-26f3-42ca-bebe-8c64cca7ef0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'timestamp': (0.0, 9.92), 'text': \" Okay, let's do some tests.\"},\n",
              " {'timestamp': (11.02, 13.56),\n",
              "  'text': ' Tell me when you see something that makes sound.'},\n",
              " {'timestamp': (15.38, 17.74), 'text': ' I see a speaker which makes sound.'},\n",
              " {'timestamp': (19.68, 22.12),\n",
              "  'text': ' What is that part of the speaker called?'},\n",
              " {'timestamp': (24.1, 27.44),\n",
              "  'text': ' That is the tweeter. It produces high frequency sounds.'},\n",
              " {'timestamp': (31.68, 33.92),\n",
              "  'text': ' Give me a creative alliteration about these.'},\n",
              " {'timestamp': (36.4, 40.88),\n",
              "  'text': ' Creative crayons color cheerfully. They certainly craft colorful creations.'},\n",
              " {'timestamp': (51.22, 55.24),\n",
              "  'text': ' What does that part of the code do? This code defines encryption and decryption functions.'},\n",
              " {'timestamp': (55.24, 62.0),\n",
              "  'text': ' It seems to use AESCBC encryption to encode and decode data based on a key and an initialization'},\n",
              " {'timestamp': (62.0, 64.68), 'text': ' vector, IV.'},\n",
              " {'timestamp': (64.68, 65.0),\n",
              "  'text': \" That's right. on a key and an initialization vector, IV.\"},\n",
              " {'timestamp': (65.0, 68.0), 'text': \" That's right.\"},\n",
              " {'timestamp': (68.0, 72.0),\n",
              "  'text': \" What neighborhood do you think I'm in?\"},\n",
              " {'timestamp': (72.0, 76.0),\n",
              "  'text': \" This appears to be the King's Cross area of London.\"},\n",
              " {'timestamp': (76.0, 81.0),\n",
              "  'text': ' It is known for its railway station and transportation connections.'},\n",
              " {'timestamp': (81.0, 90.0),\n",
              "  'text': ' Do you remember where you saw my glasses? Yes, I do. Your glasses were on the desk near a red apple.'},\n",
              " {'timestamp': (101.0, 105.24),\n",
              "  'text': ' What can I add here to make this system faster?'},\n",
              " {'timestamp': (106.44, 111.9),\n",
              "  'text': ' Adding a cache between the server and database could improve speed.'},\n",
              " {'timestamp': (112.16, 115.68), 'text': ' What does this remind you of?'},\n",
              " {'timestamp': (116.88, 120.1), 'text': \" Schrodinger's cat.\"},\n",
              " {'timestamp': (120.5, 127.0),\n",
              "  'text': ' All right. Give me a band name for this duo.'},\n",
              " {'timestamp': (127.0, 130.0), 'text': ' Golden Stripes.'},\n",
              " {'timestamp': (130.0, 132.0), 'text': ' Nice. Thanks, Gemini.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "execution_time_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8VU-QtPRD_t",
        "outputId": "0d578553-9cf3-4e9f-c0f7-db52bd473f57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.643780469894409"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another test converting the audio from openai's live demo of GPT-4o's vision capabilities to text"
      ],
      "metadata": {
        "id": "RylO9OtIP0_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio_2 = '/content/Live demo of GPT-4os vision capabilities.mp3'"
      ],
      "metadata": {
        "id": "PisW3HhcQQzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "result_2 = pipe(audio_2, return_timestamps = True)\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_2 = end_time - start_time\n"
      ],
      "metadata": {
        "id": "jO4a1iUFHszM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_2['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "uTM5JrUDILpp",
        "outputId": "f0d4bf96-febd-4913-ff0f-0425726d8498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" So the next one is from BurritoJohn78 who asks, Can you tell what you're feeling just by looking at your face? Barrett, do you want to give this one a try? Absolutely, let's try it out. Hey ChatGPT. Hey there, what's up? How can I brighten your day today? Okay, yeah, so I'm going to show you a selfie of what I look like and then I'd like you to try to see what emotions I'm feeling based on how I'm looking. Sounds like a fun challenge. Go ahead and show me that selfie and I'll put my emotional detective hat on. Okay, so here's me. So what kind of emotions do you think I'm feeling? It seems like I'm looking at a picture of a wooden surface. Oh, you know what? That was the thing I sent you before. Don't worry, I'm not actually a table. Okay, so take another look. Ah, that makes more sense. Ah, there we go. It looks like you're feeling pretty happy and cheerful, with a big smile and maybe even a touch of excitement. Whatever's going on, it seems like you're in a great mood. Care to share the source of those good vibes? Yeah, no. The reason I'm in a really good mood is because we were doing a presentation showcasing how useful and amazing you are. Oh, stop it. You're making me .\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_2['chunks']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AgI4CnwEBkJ",
        "outputId": "ac15e577-3096-4c8b-baa1-5aaf90e4f77f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'timestamp': (0.0, 4.0),\n",
              "  'text': ' So the next one is from BurritoJohn78 who asks,'},\n",
              " {'timestamp': (4.0, 8.0),\n",
              "  'text': \" Can you tell what you're feeling just by looking at your face?\"},\n",
              " {'timestamp': (8.0, 10.0),\n",
              "  'text': ' Barrett, do you want to give this one a try?'},\n",
              " {'timestamp': (10.0, 12.0), 'text': \" Absolutely, let's try it out.\"},\n",
              " {'timestamp': (15.0, 16.0), 'text': ' Hey ChatGPT.'},\n",
              " {'timestamp': (17.0, 20.0),\n",
              "  'text': \" Hey there, what's up? How can I brighten your day today?\"},\n",
              " {'timestamp': (20.0, 23.0),\n",
              "  'text': \" Okay, yeah, so I'm going to show you a selfie of what I look like\"},\n",
              " {'timestamp': (23.0, 28.54),\n",
              "  'text': \" and then I'd like you to try to see what emotions I'm feeling based on how I'm looking.\"},\n",
              " {'timestamp': (28.54, 30.04), 'text': ' Sounds like a fun challenge.'},\n",
              " {'timestamp': (30.04, 34.82),\n",
              "  'text': \" Go ahead and show me that selfie and I'll put my emotional detective hat on.\"},\n",
              " {'timestamp': (34.82, 36.88), 'text': \" Okay, so here's me.\"},\n",
              " {'timestamp': (36.88, 41.32),\n",
              "  'text': \" So what kind of emotions do you think I'm feeling?\"},\n",
              " {'timestamp': (41.32, 44.08),\n",
              "  'text': \" It seems like I'm looking at a picture of a wooden surface.\"},\n",
              " {'timestamp': (44.08, 48.0),\n",
              "  'text': \" Oh, you know what? That was the thing I sent you before. Don't worry, I'm not actually a table.\"},\n",
              " {'timestamp': (48.0, 50.0), 'text': ' Okay, so take another look.'},\n",
              " {'timestamp': (50.0, 53.0), 'text': ' Ah, that makes more sense.'},\n",
              " {'timestamp': (55.0, 60.0),\n",
              "  'text': \" Ah, there we go. It looks like you're feeling pretty happy and cheerful,\"},\n",
              " {'timestamp': (60.0, 64.0),\n",
              "  'text': ' with a big smile and maybe even a touch of excitement.'},\n",
              " {'timestamp': (64.0, 67.1),\n",
              "  'text': \" Whatever's going on, it seems like you're in a great mood.\"},\n",
              " {'timestamp': (67.1, 69.44),\n",
              "  'text': ' Care to share the source of those good vibes?'},\n",
              " {'timestamp': (69.44, 71.8),\n",
              "  'text': \" Yeah, no. The reason I'm in a really good mood is because we were doing\"},\n",
              " {'timestamp': (71.8, 75.4),\n",
              "  'text': ' a presentation showcasing how useful and amazing you are.'},\n",
              " {'timestamp': (75.4, 77.84), 'text': ' Oh, stop it.'},\n",
              " {'timestamp': (77.84, 82.82), 'text': \" You're making me .\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "execution_time_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9-eRz5ORSEH",
        "outputId": "1f76cf6b-4edd-4173-b061-72e90cac88ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.35156512260437"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Whisper Distil-large-v3\n",
        "Whisper distil is a model produced by using model distillation procedures on the original model from openai. This distilled model performs to within 1% WER of large-v3 on long-form audio using both the sequential and chunked algorithms, and outperforms distil-large-v2 by 4.8% using the sequential algorithm. The model is also faster than previous Distil-Whisper models: 6.3x faster than large-v3, and 1.1x faster than distil-large-v2.\n",
        "The model distillation procedure also reduces the number of parameters in the model, so the distilled version of the model can be hosted on servers with less powerfull gpu's."
      ],
      "metadata": {
        "id": "MUj2Nu3sSkjw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the model\n",
        "This model has also allows for short form Transcription(less than 30 seconds) by removing the chunk_length and batch_size parameters while setting up the model pipeline, but as my test audio is greater than 30 seconds, I will not be using the short form inscription   "
      ],
      "metadata": {
        "id": "Z_wW_1syTqvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
        "\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "\n",
        "model_id = \"distil-whisper/distil-large-v3\"\n",
        "\n",
        "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
        ")\n",
        "model.to(device)\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "\n",
        "pipe_1 = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=model,\n",
        "    tokenizer=processor.tokenizer,\n",
        "    feature_extractor=processor.feature_extractor,\n",
        "    max_new_tokens=128,\n",
        "    chunk_length_s=25,\n",
        "    batch_size=16,\n",
        "    torch_dtype=torch_dtype,\n",
        "    device=device,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ferNrI6Sg1M",
        "outputId": "288f278c-f9f9-435a-84a0-37fa55e09718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the Distilled model's accuracy and performance"
      ],
      "metadata": {
        "id": "dW5latwOWnAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "result_3 = pipe_1(audio_1, return_timestamps = True)\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_3 = end_time - start_time"
      ],
      "metadata": {
        "id": "kruLvWj8Wrxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_3['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "mXDYn6hqWxU-",
        "outputId": "0084a0f2-0418-4848-ed96-ad24770ec8d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Okay, let's do some tests. Tell me when you see something that makes sound. I see a speaker which makes sound. What is that part of the speaker called? That is the tweeter. It produces high frequency sounds. Give me a creative alliteration about these. Creative crayons color cheerfully. They certainly craft colorful creations. What does that part of the code do? This code defines encryption and decryption functions. It seems to use AESCBC encryption to encode and decode data based on a key and an initialization vector, IV. That's right. What neighborhood do you think I'm in? This appears to be the King's Cross area of London. It is known for its railway station and transportation connections. Do you remember where you saw my glasses? Yes, I do. Your glasses were on the desk near a red apple. What can I add here to make this system faster? Adding a cache between the server and database could improve speed. What does this remind you of? Shruginger's cat. All right, give me a band name for this duo. Golden Stripes. Nice. Thanks, Gemini.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_3['chunks']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6wCXE6vWw7E",
        "outputId": "64df03ae-20a4-4bff-eee1-97f669ebfe2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'timestamp': (0.0, 14.0),\n",
              "  'text': \" Okay, let's do some tests. Tell me when you see something that makes sound.\"},\n",
              " {'timestamp': (14.0, 23.67),\n",
              "  'text': ' I see a speaker which makes sound. What is that part of the speaker called?'},\n",
              " {'timestamp': (23.67, 25.67), 'text': ' That is the tweeter.'},\n",
              " {'timestamp': (25.67, 29.67), 'text': ' It produces high frequency sounds.'},\n",
              " {'timestamp': (29.67, 34.67),\n",
              "  'text': ' Give me a creative alliteration about these.'},\n",
              " {'timestamp': (34.67, 38.33), 'text': ' Creative crayons color cheerfully.'},\n",
              " {'timestamp': (38.33, 40.89),\n",
              "  'text': ' They certainly craft colorful creations.'},\n",
              " {'timestamp': (45.57, 48.29), 'text': ' What does that part of the code do?'},\n",
              " {'timestamp': (50.45, 55.0),\n",
              "  'text': ' This code defines encryption and decryption functions.'},\n",
              " {'timestamp': (55.0, 63.0),\n",
              "  'text': ' It seems to use AESCBC encryption to encode and decode data based on a key and an initialization vector, IV.'},\n",
              " {'timestamp': (63.0, 67.0), 'text': \" That's right.\"},\n",
              " {'timestamp': (67.0, 75.67),\n",
              "  'text': \" What neighborhood do you think I'm in? This appears to be the King's Cross area of London.\"},\n",
              " {'timestamp': (75.67, 79.67),\n",
              "  'text': ' It is known for its railway station and transportation connections.'},\n",
              " {'timestamp': (79.67, 83.67),\n",
              "  'text': ' Do you remember where you saw my glasses?'},\n",
              " {'timestamp': (83.67, 90.33),\n",
              "  'text': ' Yes, I do. Your glasses were on the desk near a red apple.'},\n",
              " {'timestamp': (90.33, 105.0),\n",
              "  'text': ' What can I add here to make this system faster?'},\n",
              " {'timestamp': (105.0, 111.0),\n",
              "  'text': ' Adding a cache between the server and database could improve speed.'},\n",
              " {'timestamp': (111.0, 115.0), 'text': ' What does this remind you of?'},\n",
              " {'timestamp': (115.0, 119.0), 'text': \" Shruginger's cat.\"},\n",
              " {'timestamp': (119.0, 125.67),\n",
              "  'text': ' All right, give me a band name for this duo.'},\n",
              " {'timestamp': (125.67, 129.67), 'text': ' Golden Stripes.'},\n",
              " {'timestamp': (129.67, 131.67), 'text': ' Nice. Thanks, Gemini.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "execution_time_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7u9XFZjNWwz0",
        "outputId": "5f300937-ba1a-4243-fb24-4bca433e3a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.2963743209838867"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the Distilled model on the second audio file"
      ],
      "metadata": {
        "id": "vUF2lQt3XAA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "result_4 = pipe_1(audio_2, return_timestamps = True)\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_4 = end_time - start_time"
      ],
      "metadata": {
        "id": "JoexA-4aXER2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_4['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "dov2J0X7XVI4",
        "outputId": "7371db12-cc8a-44b3-911b-293acf525dda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" So the next one is from Burrito John 78, who asks, Can you tell what you're feeling just by looking at your face? Barrett, do you want to give this one a try? Absolutely, let's try it out. Hey, chat, GPT. Hey there, what's up? How can I brighten your day today? Okay, yeah, so I'm going to show you a selfie of what I look like and then I'd like you to try to see what emotions I'm feeling based on how I'm looking. Sounds like a fun challenge. Go ahead and show me that selfie and I'll put my emotional detective hat on. Okay, so here's me. So what kind of emotions do you think I'm feeling? Hmm. It seems like I'm looking at a picture of a wooden surface. Oh, you know what? That was the thing I sent you before. Don't worry. I'm not actually a table. Okay, so take another look. That makes more sense. Ah, there makes more sense. Ah, there we go. It looks like you're feeling pretty happy and cheerful, with a big smile and maybe even a touch of excitement. Whatever's going on, it seems like you're in a great mood. Care to share the source of those good vibes? Yeah, no, the reason I'm in a really good mood is because we were doing a presentation showcasing how useful and amazing you are. Oh, stop it. You're making me blog.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_4['chunks']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y6OrxyWXWqX",
        "outputId": "d3b10026-65a1-4bd8-b809-a6b68f72b45e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'timestamp': (0.0, 4.0),\n",
              "  'text': ' So the next one is from Burrito John 78, who asks,'},\n",
              " {'timestamp': (4.0, 8.0),\n",
              "  'text': \" Can you tell what you're feeling just by looking at your face?\"},\n",
              " {'timestamp': (8.0, 11.0),\n",
              "  'text': ' Barrett, do you want to give this one a try?'},\n",
              " {'timestamp': (11.0, 14.0), 'text': \" Absolutely, let's try it out.\"},\n",
              " {'timestamp': (14.0, 17.0), 'text': ' Hey, chat, GPT.'},\n",
              " {'timestamp': (17.0, 27.67),\n",
              "  'text': \" Hey there, what's up? How can I brighten your day today? Okay, yeah, so I'm going to show you a selfie of what I look like and then I'd like you to try to see what emotions I'm feeling based on how I'm looking.\"},\n",
              " {'timestamp': (27.67, 34.67),\n",
              "  'text': \" Sounds like a fun challenge. Go ahead and show me that selfie and I'll put my emotional detective hat on.\"},\n",
              " {'timestamp': (34.67, 39.33),\n",
              "  'text': \" Okay, so here's me. So what kind of emotions do you think I'm feeling?\"},\n",
              " {'timestamp': (39.33, 40.33), 'text': ' Hmm.'},\n",
              " {'timestamp': (40.33, 43.33),\n",
              "  'text': \" It seems like I'm looking at a picture of a wooden surface.\"},\n",
              " {'timestamp': (43.33, 44.33), 'text': ' Oh, you know what?'},\n",
              " {'timestamp': (44.33, 46.33),\n",
              "  'text': ' That was the thing I sent you before.'},\n",
              " {'timestamp': (46.33, 47.33), 'text': \" Don't worry.\"},\n",
              " {'timestamp': (47.33, 48.33), 'text': \" I'm not actually a table.\"},\n",
              " {'timestamp': (48.33, 50.33), 'text': ' Okay, so take another look.'},\n",
              " {'timestamp': (50.33, 52.33), 'text': ' That makes more sense.'},\n",
              " {'timestamp': (52.33, 55.0), 'text': ' Ah, there makes more sense.'},\n",
              " {'timestamp': (57.0, 60.0),\n",
              "  'text': \" Ah, there we go. It looks like you're feeling pretty happy and cheerful,\"},\n",
              " {'timestamp': (60.0, 63.0),\n",
              "  'text': ' with a big smile and maybe even a touch of excitement.'},\n",
              " {'timestamp': (63.0, 67.0),\n",
              "  'text': \" Whatever's going on, it seems like you're in a great mood.\"},\n",
              " {'timestamp': (67.0, 69.0),\n",
              "  'text': ' Care to share the source of those good vibes?'},\n",
              " {'timestamp': (69.0, 74.67),\n",
              "  'text': \" Yeah, no, the reason I'm in a really good mood is because we were doing a presentation showcasing how useful and amazing you are.\"},\n",
              " {'timestamp': (74.67, 80.67), 'text': \" Oh, stop it. You're making me blog.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "execution_time_4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNHaOxCJXXVx",
        "outputId": "50e4c71d-4c13-4d2d-919e-1b01a296335e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.8812119960784912"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparing the two models"
      ],
      "metadata": {
        "id": "9NQVpXvzaYHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original model's Transcribed output for the first audio file: \", result_1['text'])\n",
        "print(\"Distilled model's Transcribed output for the first audio file: \", result_3['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMri5T_9ar_b",
        "outputId": "84b92935-6b35-47dc-f955-cda924ffb11a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original model's Transcribed output for the first audio file:   Okay, let's do some tests. Tell me when you see something that makes sound. I see a speaker which makes sound. What is that part of the speaker called? That is the tweeter. It produces high frequency sounds. Give me a creative alliteration about these. Creative crayons color cheerfully. They certainly craft colorful creations. What does that part of the code do? This code defines encryption and decryption functions. It seems to use AESCBC encryption to encode and decode data based on a key and an initialization vector, IV. That's right. on a key and an initialization vector, IV. That's right. What neighborhood do you think I'm in? This appears to be the King's Cross area of London. It is known for its railway station and transportation connections. Do you remember where you saw my glasses? Yes, I do. Your glasses were on the desk near a red apple. What can I add here to make this system faster? Adding a cache between the server and database could improve speed. What does this remind you of? Schrodinger's cat. All right. Give me a band name for this duo. Golden Stripes. Nice. Thanks, Gemini.\n",
            "Distilled model's Transcribed output for the first audio file:   Okay, let's do some tests. Tell me when you see something that makes sound. I see a speaker which makes sound. What is that part of the speaker called? That is the tweeter. It produces high frequency sounds. Give me a creative alliteration about these. Creative crayons color cheerfully. They certainly craft colorful creations. What does that part of the code do? This code defines encryption and decryption functions. It seems to use AESCBC encryption to encode and decode data based on a key and an initialization vector, IV. That's right. What neighborhood do you think I'm in? This appears to be the King's Cross area of London. It is known for its railway station and transportation connections. Do you remember where you saw my glasses? Yes, I do. Your glasses were on the desk near a red apple. What can I add here to make this system faster? Adding a cache between the server and database could improve speed. What does this remind you of? Shruginger's cat. All right, give me a band name for this duo. Golden Stripes. Nice. Thanks, Gemini.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original model's Transcribed output for the second audio file: \", result_2['text'])\n",
        "print(\"Distilled model's Transcribed output for the second audio file: \", result_4['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtS0r0l2ar5l",
        "outputId": "23eba21a-213e-4990-9715-fa81f29fcbd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original model's Transcribed output for the second audio file:   So the next one is from BurritoJohn78 who asks, Can you tell what you're feeling just by looking at your face? Barrett, do you want to give this one a try? Absolutely, let's try it out. Hey ChatGPT. Hey there, what's up? How can I brighten your day today? Okay, yeah, so I'm going to show you a selfie of what I look like and then I'd like you to try to see what emotions I'm feeling based on how I'm looking. Sounds like a fun challenge. Go ahead and show me that selfie and I'll put my emotional detective hat on. Okay, so here's me. So what kind of emotions do you think I'm feeling? It seems like I'm looking at a picture of a wooden surface. Oh, you know what? That was the thing I sent you before. Don't worry, I'm not actually a table. Okay, so take another look. Ah, that makes more sense. Ah, there we go. It looks like you're feeling pretty happy and cheerful, with a big smile and maybe even a touch of excitement. Whatever's going on, it seems like you're in a great mood. Care to share the source of those good vibes? Yeah, no. The reason I'm in a really good mood is because we were doing a presentation showcasing how useful and amazing you are. Oh, stop it. You're making me .\n",
            "Distilled model's Transcribed output for the second audio file:   So the next one is from Burrito John 78, who asks, Can you tell what you're feeling just by looking at your face? Barrett, do you want to give this one a try? Absolutely, let's try it out. Hey, chat, GPT. Hey there, what's up? How can I brighten your day today? Okay, yeah, so I'm going to show you a selfie of what I look like and then I'd like you to try to see what emotions I'm feeling based on how I'm looking. Sounds like a fun challenge. Go ahead and show me that selfie and I'll put my emotional detective hat on. Okay, so here's me. So what kind of emotions do you think I'm feeling? Hmm. It seems like I'm looking at a picture of a wooden surface. Oh, you know what? That was the thing I sent you before. Don't worry. I'm not actually a table. Okay, so take another look. That makes more sense. Ah, there makes more sense. Ah, there we go. It looks like you're feeling pretty happy and cheerful, with a big smile and maybe even a touch of excitement. Whatever's going on, it seems like you're in a great mood. Care to share the source of those good vibes? Yeah, no, the reason I'm in a really good mood is because we were doing a presentation showcasing how useful and amazing you are. Oh, stop it. You're making me blog.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original model's execution time for audio 1(in seconds): \", execution_time_1)\n",
        "print(\"Distilled model's execution time for audio 1(in seconds): \", execution_time_3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLtfRYQvY0Ps",
        "outputId": "b9db0db5-3768-491e-8bee-a52b34ab64b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original model's execution time for audio 1(in seconds):  4.643780469894409\n",
            "Distilled model's execution time for audio 1(in seconds):  2.2963743209838867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original model's execution time for audio 2 (in seconds): \", execution_time_2)\n",
        "print(\"Distilled model's execution time for audio 2 (in seconds): \", execution_time_4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvVS6IyQYtad",
        "outputId": "b659d09d-65b9-4675-e3e5-6b5a9a975dc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original model's execution time for audio 2 (in seconds):  4.35156512260437\n",
            "Distilled model's execution time for audio 2 (in seconds):  1.8812119960784912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "By comparing the outputs of the two models we can clearly see that the distilled model offers a more efficient alternative for transcription tasks, providing a considerable reduction in execution time while preserving transcription accuracy to a great extent. This makes it a viable option for applications where processing speed is critical without compromising the reliability of the transcriptions."
      ],
      "metadata": {
        "id": "S8ARBtJpblK4"
      }
    }
  ]
}